{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72245e6e-3bdb-4b26-92e4-a07c2cc84d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Required libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Imports for all tasks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"Setup complete. Required libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5264d9f3-9176-4b40-8f85-d043610c926b",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7502f83f-98e6-4f4f-b7e5-c0c7d88a244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter sentences to generate embeddings (type 'done' when finished):\n",
      "> apples 5 pcs 7$\n",
      "> milk 2 pcs 12$\n",
      "> bread 1 pcs 6$\n",
      "> done\n",
      "\n",
      "Generated Sentence Embeddings:\n",
      "-----------------------------\n",
      "Sentence 1: apples 5 pcs 7$\n",
      "Embedding (first 5 of 384 dimensions): [-0.01811078  0.04169159  0.06918947  0.02195263  0.01449898]...\n",
      "\n",
      "Sentence 2: milk 2 pcs 12$\n",
      "Embedding (first 5 of 384 dimensions): [ 0.03493364  0.00117    -0.00209289 -0.01365882 -0.00412777]...\n",
      "\n",
      "Sentence 3: bread 1 pcs 6$\n",
      "Embedding (first 5 of 384 dimensions): [-0.00151778  0.02710414 -0.01061682  0.00802708 -0.07450908]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Task 1: Collect sentences\n",
    "sentences_task1 = []\n",
    "print(\"Enter sentences to generate embeddings (type 'done' when finished):\")\n",
    "\n",
    "while True:\n",
    "    sentence = input(\"> \")\n",
    "    if sentence.lower() == 'done':\n",
    "        break\n",
    "    sentences_task1.append(sentence)\n",
    "\n",
    "if not sentences_task1:\n",
    "    print(\"No sentences provided.\")\n",
    "else:\n",
    "    # Generate and display embeddings\n",
    "    model_task1 = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model_task1.encode(sentences_task1, batch_size=32, show_progress_bar=False)\n",
    "\n",
    "    print(\"\\nGenerated Sentence Embeddings:\")\n",
    "    print(\"-----------------------------\")\n",
    "    for i, (sentence, embedding) in enumerate(zip(sentences_task1, embeddings), 1):\n",
    "        print(f\"Sentence {i}: {sentence}\")\n",
    "        print(f\"Embedding (first 5 of 384 dimensions): {embedding[:5]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f770a2d-b672-48ea-80b9-b80f198ff8f0",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b7b279-6298-49d0-a884-622dfe430c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTL model initialized.\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Define the MTL model\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, num_categories=5):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.backbone = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.embedding_dim = 384\n",
    "        self.classification_head = nn.Linear(self.embedding_dim, num_categories)\n",
    "        self.regression_head = nn.Linear(self.embedding_dim, 1)\n",
    "    \n",
    "    def forward(self, sentences):\n",
    "        embeddings = self.backbone.encode(sentences, convert_to_tensor=True, \n",
    "                                        batch_size=32, show_progress_bar=False)\n",
    "        embeddings = embeddings.to(self.classification_head.weight.device)\n",
    "        class_logits = self.classification_head(embeddings)\n",
    "        quantity_pred = self.regression_head(embeddings)\n",
    "        return class_logits, quantity_pred\n",
    "\n",
    "# Initialize model\n",
    "model_task2 = MultiTaskModel(num_categories=5)\n",
    "category_labels = [\"Fruit\", \"Dairy\", \"Bakery\", \"Meat\", \"Other\"]\n",
    "print(\"MTL model initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e87e960-c083-4d94-9486-909566a4986a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the following receipt items:\n",
      "1. 2x Apples $1.99\n",
      "2. Milk 1L $2.50\n",
      "3. 3x Bread $3.00\n",
      "4. Chicken Breast 500g $5.99\n",
      "5. 4x Bananas $2.40\n",
      "\n",
      "Multi-Task Predictions:\n",
      "----------------------\n",
      "Sentence 1: 2x Apples $1.99\n",
      "Predicted Category: Other\n",
      "Predicted Quantity: -0.02\n",
      "\n",
      "Sentence 2: Milk 1L $2.50\n",
      "Predicted Category: Other\n",
      "Predicted Quantity: -0.01\n",
      "\n",
      "Sentence 3: 3x Bread $3.00\n",
      "Predicted Category: Dairy\n",
      "Predicted Quantity: -0.00\n",
      "\n",
      "Sentence 4: Chicken Breast 500g $5.99\n",
      "Predicted Category: Other\n",
      "Predicted Quantity: -0.02\n",
      "\n",
      "Sentence 5: 4x Bananas $2.40\n",
      "Predicted Category: Other\n",
      "Predicted Quantity: -0.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Hardcoded sentences and predictions\n",
    "sentences_task2 = [\n",
    "    \"2x Apples $1.99\", \"Milk 1L $2.50\", \"3x Bread $3.00\",\n",
    "    \"Chicken Breast 500g $5.99\", \"4x Bananas $2.40\"\n",
    "]\n",
    "\n",
    "print(\"Processing the following receipt items:\")\n",
    "for i, sentence in enumerate(sentences_task2, 1):\n",
    "    print(f\"{i}. {sentence}\")\n",
    "\n",
    "# Get predictions\n",
    "model_task2.eval()\n",
    "with torch.no_grad():\n",
    "    class_logits, quantity_pred = model_task2(sentences_task2)\n",
    "    class_probs = torch.softmax(class_logits, dim=1)\n",
    "    class_indices = torch.argmax(class_probs, dim=1)\n",
    "    \n",
    "    print(\"\\nMulti-Task Predictions:\")\n",
    "    print(\"----------------------\")\n",
    "    for i, (sentence, category_idx, qty) in enumerate(zip(sentences_task2, class_indices, quantity_pred)):\n",
    "        category = category_labels[category_idx.item()]\n",
    "        quantity = qty.item()\n",
    "        print(f\"Sentence {i+1}: {sentence}\")\n",
    "        print(f\"Predicted Category: {category}\")\n",
    "        print(f\"Predicted Quantity: {quantity:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f39178-49ab-40db-a166-b47ccc2ebed4",
   "metadata": {},
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72aa2c-5873-4d2a-9792-7d6829ccbc93",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca6a2daf-619d-4a8b-ab08-987ac07d1cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Loss A: 0.6974, Loss B: 0.6898, Total Loss: 1.3873\n",
      "Accuracy A: 0.3333, Accuracy B: 0.6667\n",
      "\n",
      "Epoch 2/3\n",
      "Loss A: 0.6972, Loss B: 0.6895, Total Loss: 1.3866\n",
      "Accuracy A: 0.3333, Accuracy B: 0.6667\n",
      "\n",
      "Epoch 3/3\n",
      "Loss A: 0.6969, Loss B: 0.6891, Total Loss: 1.3860\n",
      "Accuracy A: 0.3333, Accuracy B: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hypothetical Sentences\n",
    "sentences = [\"I love ML!\", \"This is boring.\", \"Transformers rock!\"]\n",
    "\n",
    "# Hypothetical Labels (Task A: Tech vs Non-Tech, Task B: Sentiment)\n",
    "labels_a = torch.tensor([1, 0, 1], dtype=torch.long)  # Tech: 1, Non-Tech: 0\n",
    "labels_b = torch.tensor([1, 0, 1], dtype=torch.long)  # Positive: 1, Negative: 0\n",
    "\n",
    "# Encode Sentences to Numeric Embeddings\n",
    "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sentence_embeddings = torch.tensor(encoder.encode(sentences))\n",
    "\n",
    "# Define Multi-Task Model (Assuming it has two outputs)\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, num_categories=2):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.shared_layer = nn.Linear(384, 128)  # 384-d input (MiniLM)\n",
    "        self.task_head_a = nn.Linear(128, num_categories)  # Task A Head\n",
    "        self.task_head_b = nn.Linear(128, num_categories)  # Task B Head\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_output = torch.relu(self.shared_layer(x))\n",
    "        logits_a = self.task_head_a(shared_output)  # Tech/Non-Tech\n",
    "        logits_b = self.task_head_b(shared_output)  # Sentiment\n",
    "        return logits_a, logits_b\n",
    "\n",
    "# Initialize Model, Optimizer, and Loss Function\n",
    "model = MultiTaskModel(num_categories=2)\n",
    "optimizer = Adam(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training Loop (3 Epochs for Demonstration)\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward Pass\n",
    "    logits_a, logits_b = model(sentence_embeddings)\n",
    "\n",
    "    # Compute Loss for Each Task\n",
    "    loss_a = loss_fn(logits_a, labels_a)\n",
    "    loss_b = loss_fn(logits_b, labels_b)\n",
    "    total_loss = loss_a + loss_b  # Combined loss\n",
    "\n",
    "    # Backward Pass\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute Predictions\n",
    "    preds_a = torch.argmax(logits_a, dim=1)\n",
    "    preds_b = torch.argmax(logits_b, dim=1)\n",
    "\n",
    "    # Compute Accuracy for Each Task\n",
    "    acc_a = (preds_a == labels_a).float().mean().item()\n",
    "    acc_b = (preds_b == labels_b).float().mean().item()\n",
    "\n",
    "    # Print Epoch Summary\n",
    "    print(f\"Epoch {epoch+1}/3\")\n",
    "    print(f\"Loss A: {loss_a.item():.4f}, Loss B: {loss_b.item():.4f}, Total Loss: {total_loss.item():.4f}\")\n",
    "    print(f\"Accuracy A: {acc_a:.4f}, Accuracy B: {acc_b:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79524d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
